# lightning.pytorch==2.0.0
name: siglip-giant-aug
version: v11

seed_everything: 42
trainer:
  accelerator: auto
  precision: 16-mixed
  max_epochs: 300
  # deterministic: true
  deterministic: false
  benchmark: true  # CUDA 벤치마킹 활성화로 성능 향상
  plugins:
    - AsyncCheckpointIO
  callbacks:
    - class_path: WandbAlert
      init_args:
        monitor: ${model_ckpt.monitor}
        mode: ${model_ckpt.mode}

# Model configs
model:
  class_path: models.car_classifier.CarClassifier
  init_args:
    net:
      class_path: nets.timm.TimmModel
      init_args:
        model_name: "eva02_large_patch14_448.mim_m38m_ft_in22k_in1k"
        num_classes: 396
        pretrained: true
    loss_fn:
      class_path: losses.pmd_loss.ProgressiveMarginDecayingLoss
      init_args:
        margin_init: 0.5
        margin_final: 0.1
        num_epochs: ${trainer.max_epochs}
    learning_rate: 0.0001
    weight_decay: 0.0001
    vis_per_batch: 4

# Data configs
data:
  class_path: datasets.car_dataset.CarDataModule
  init_args:
    root: datasets  # Update with your actual path
    batch_size: 4
    transforms:
      class_path: transforms.car_transforms.CarTransforms
      init_args:
        img_size: 448
    num_workers: 4

# optimizer:
#   class_path: SGD
#   init_args:
#     lr: 0.1
#     momentum: 0.9
#     weight_decay: 5e-4

lr_scheduler:
  class_path: LinearWarmupCosineAnnealingLR
  init_args:
    warmup_epochs: 20
    max_epochs: ${trainer.max_epochs}

early_stopping:
  monitor: val/acc
  patience: 1000
  mode: max

model_ckpt:
  # dirpath: "gs://ecstatic-kirch-iqa-dacon"
  monitor: val/acc
  mode: max
  filename: "best-ep={epoch:02d}-val_acc={val/acc:.4f}"
  auto_insert_metric_name: false
# ckpt_path: logs/debug-resume/version_0/fit/checkpoints/last.ckpt

