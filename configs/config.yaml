# lightning.pytorch==2.0.0
name: my_experiment
version: my_version

seed_everything: 42
trainer:
  accelerator: auto
  precision: 16-mixed
  max_epochs: 100
  deterministic: true
  plugins:
    - AsyncCheckpointIO
  callbacks:
    - class_path: WandbAlert
      init_args:
        monitor: ${model_ckpt.monitor}
        mode: ${model_ckpt.mode}

# Model configs
model:
  class_path: models.car_classifier.CarClassifier
  init_args:
    net:
      class_path: nets.tresnet.TResNetL
      init_args:
        num_classes: 394
        pretrained: true
    loss:
      class_path: losses.car_loss.CarLoss
      init_args:
        margin_init: 0.5
        margin_final: 0.1
        num_epochs: ${trainer.max_epochs}
    learning_rate: 0.0001
    weight_decay: 0.0001
    vis_per_batch: 4

# Data configs
data:
  class_path: datasets.car_dataset.CarDataModule
  init_args:
    root: datasets  # Update with your actual path
    batch_size: 32
    transforms:
      class_path: transforms.car_transforms.CarTransforms
    num_workers: 4

optimizer:
  class_path: SGD
  init_args:
    lr: 0.1
    momentum: 0.9
    weight_decay: 5e-4

lr_scheduler:
  class_path: LinearWarmupCosineAnnealingLR
  init_args:
    warmup_epochs: 20
    max_epochs: ${trainer.max_epochs}

early_stopping:
  monitor: val/acc
  patience: 1000
  mode: max

model_ckpt:
  # dirpath: "gs://ecstatic-kirch-iqa-dacon"
  monitor: val/acc
  mode: max
  filename: "best-ep={epoch:02d}-val_acc={val/acc:.4f}"
  auto_insert_metric_name: false
# ckpt_path: logs/debug-resume/version_0/fit/checkpoints/last.ckpt

