# lightning.pytorch==2.0.0
name: fgvc-tresnet-xl-fold1
version: v1

seed_everything: 42
trainer:
  accelerator: auto
  precision: 16-mixed
  max_epochs: 300
  # deterministic: true
  deterministic: false
  benchmark: true  # CUDA 벤치마킹 활성화로 성능 향상
  plugins:
    - AsyncCheckpointIO
  callbacks:
    - class_path: WandbAlert
      init_args:
        monitor: ${model_ckpt.monitor}
        mode: ${model_ckpt.mode}

# Model configs
model:
  class_path: models.fgvc.TResNetAntiNoiseCarClassifier
  init_args:
    backbone_name: "tresnet_xl"  # tresnet_m, tresnet_l, tresnet_xl 중 선택
    pretrained: true
    img_size: 448
    num_classes: 400
    learning_rate: 1e-4  # 소규모 데이터셋이므로 낮은 학습률
    weight_decay: 1e-3   # 과적합 방지를 위해 높은 weight decay
    alpha: 1.0
    use_sam: false  # 소규모 데이터에서는 AdamW가 더 안정적
    teacher_path: null
    distill_phase_ratio: 0.3  # distillation 비율 감소
    vis_per_batch: 8

# Data configs
data:
  class_path: datasets.car_dataset.CarDataModule
  init_args:
    root: datasets  # Update with your actual path
    batch_size: 32
    transforms:
      class_path: transforms.fgvc.SmallScaleCarTransforms
      init_args:
        img_size: 448
        use_advanced_aug: true  # 고급 증강 사용
    num_workers: 4

# optimizer:
#   class_path: SGD
#   init_args:
#     lr: 0.1
#     momentum: 0.9
#     weight_decay: 5e-4

lr_scheduler:
  class_path: LinearWarmupCosineAnnealingLR
  init_args:
    warmup_epochs: 20
    max_epochs: ${trainer.max_epochs}

early_stopping:
  monitor: val/acc
  patience: 1000
  mode: max

model_ckpt:
  # dirpath: "gs://ecstatic-kirch-iqa-dacon"
  monitor: val/acc
  mode: max
  filename: "best-ep={epoch:02d}-val_acc={val/acc:.4f}"
  auto_insert_metric_name: false
# ckpt_path: logs/debug-resume/version_0/fit/checkpoints/last.ckpt
